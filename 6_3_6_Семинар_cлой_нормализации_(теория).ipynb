{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuZqrwAAMIKTcf8Mpd4mG1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/303592/step/6\n",
        "\n",
        "Мы познакомились поближе с нормализацией \"по батчу\". Для упрощения дальнейшего изложения остановимся на случае трехмерного тензора на входе слоя, если же размерность входа больше трех, то вытянем все размерности кроме первых двух в одну размерность.\n",
        "\n",
        "Бывает нормировка не только по батчу, но и по другим измерениям.\n",
        "\n",
        "Обратите внимание на изображения ниже.\n",
        "\n",
        "<img src=\"https://ucarecdn.com/d1894e62-5608-43ce-80a0-f767d1875ff9/\">\n",
        "\n",
        "Где:\n",
        "\n",
        "*   C - число каналов на входе.\n",
        "*   N - размер батча.\n",
        "*   H, W - размерность по последней (третьей) размерности входа.\n",
        "\n",
        "\n",
        "На изображении можно увидеть следующие виды нормализации:\n",
        "\n",
        "*   По батчу.\n",
        "*   По каналу.\n",
        "*   По инстансу.\n",
        "*   По группе.\n",
        "\n",
        "Кроме указанных видов, также существует множество других, выходящих за рамки нашего урока.\n",
        "\n",
        "Указанные виды нормализации мы рассмотрим в дальнейших шагах.\n",
        "\n",
        "## Виды нормализации в машинном обучении:\n",
        "\n",
        "Нормализация данных - это важный этап в обработке данных для обучения моделей машинного обучения. Она позволяет привести данные к общему масштабу и улучшить производительность модели. Вот объяснение разных видов нормализации:\n",
        "\n",
        "**1. Нормализация по батчу (Batch normalization):**\n",
        "\n",
        "* **Описание:** Этот метод применяется во время обучения модели. Данные нормализуются в рамках каждого батча (небольшой группы данных) перед подачей на вход нейронной сети.\n",
        "* **Как работает:**\n",
        "    * Вычисляются среднее значение и дисперсия для каждого признака в батче.\n",
        "    * Данные в батче стандартизируются по этим значениям.\n",
        "    * Используются обучаемые параметры (гамма и бета), чтобы скорректировать масштаб и сдвиг стандартизированных данных.\n",
        "* **Преимущества:**\n",
        "    * Ускоряет обучение моделей.\n",
        "    * Предотвращает проблемы с градиентным спуском, связанные с изменением масштаба признаков.\n",
        "    * Улучшает обобщающую способность модели.\n",
        "* **Недостатки:**\n",
        "    * Может быть вычислительно дорогостоящим для больших батчей.\n",
        "    * Могут быть сложности с обработкой потоковых данных.\n",
        "\n",
        "**2. Нормализация по каналу (Channel normalization):**\n",
        "\n",
        "* **Описание:** Этот метод применяется в задачах компьютерного зрения, где данные представлены в виде тензоров с каналами, например, изображения RGB.\n",
        "* **Как работает:**\n",
        "    * Вычисляются среднее значение и дисперсия по каждому каналу (например, красный, зеленый, синий).\n",
        "    * Данные в каждом канале стандартизируются по этим значениям.\n",
        "* **Преимущества:**\n",
        "    * Помогает модели лучше усваивать информацию из разных каналов изображения.\n",
        "    * Улучшает обобщающую способность модели.\n",
        "* **Недостатки:**\n",
        "    * Может быть менее эффективным, чем батчевая нормализация.\n",
        "\n",
        "**3. Нормализация по инстансу (Instance normalization):**\n",
        "\n",
        "* **Описание:**  Этот метод применяется для нормализации данных внутри каждого образца (инстанса).\n",
        "* **Как работает:**\n",
        "    * Вычисляются среднее значение и дисперсия для каждого образца.\n",
        "    * Данные в образце стандартизируются по этим значениям.\n",
        "* **Преимущества:**\n",
        "    * Может быть полезен для задач с переменным масштабом данных.\n",
        "    * Способствует улучшению качества изображения.\n",
        "* **Недостатки:**\n",
        "    * Может не работать так хорошо, как батчевая нормализация для больших наборов данных.\n",
        "\n",
        "**4. Нормализация по группе (Group normalization):**\n",
        "\n",
        "* **Описание:** Этот метод сочетает в себе преимущества батчевой и инстанс-нормализации.\n",
        "* **Как работает:**\n",
        "    * Данные разбиваются на группы по каналам.\n",
        "    * Вычисляются среднее значение и дисперсия для каждой группы.\n",
        "    * Данные в каждой группе стандартизируются по этим значениям.\n",
        "* **Преимущества:**\n",
        "    * Может быть более устойчивым к изменениям размера батча.\n",
        "    * Часто работает лучше, чем батчевая нормализация, особенно для небольших батчей.\n",
        "* **Недостатки:**\n",
        "    * Может быть более сложным в реализации.\n",
        "\n",
        "\n",
        "**Выбор метода нормализации зависит от конкретной задачи, размера набора данных, архитектуры модели и других факторов.**\n",
        "\n",
        "**Дополнительная информация:**\n",
        "* **Стандартизация:** Это отдельный метод, который масштабирует данные, чтобы они имели среднее значение 0 и дисперсию 1.\n",
        "* **MinMax scaling:** Этот метод масштабирует данные в диапазон от 0 до 1.\n",
        "\n",
        "Помимо описанных выше, существует еще несколько видов нормализации, используемых в машинного обучении. Важно выбрать подходящий метод для конкретной задачи.\n"
      ],
      "metadata": {
        "id": "0GxCb9xCSl1L"
      }
    }
  ]
}